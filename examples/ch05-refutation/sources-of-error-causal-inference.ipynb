{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources of error in causal inference: Modeling, Identification and Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate the different errors in a causal inference pipeline, we simulate three datasets. \n",
    "\n",
    "The dataset construction and analysis is taken from Sharma et al. (2021). [DoWhy: Addressing Challenges in Expressing and Validating Assumptions](https://arxiv.org/abs/2108.13518)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import dowhy\n",
    "from dowhy.causal_estimators.linear_regression_estimator import LinearRegressionEstimator\n",
    "from dowhy.causal_identifier import identify_effect\n",
    "from dowhy.causal_graph import CausalGraph\n",
    "\n",
    "# Avoid printing dataconversion warnings from sklearn\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Config dict to set the logging level\n",
    "import logging.config\n",
    "DEFAULT_LOGGING = {\n",
    "    'version': 1,\n",
    "    'disable_existing_loggers': False,\n",
    "    'loggers': {\n",
    "        '': {\n",
    "            'level': 'WARN',\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "logging.config.dictConfig(DEFAULT_LOGGING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SIMS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test (Mediator)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "\n",
    "def gen_data_m(num_samples= 1000, p=0.95):\n",
    "    \"\"\"Generate data with a mediator. \n",
    "    \n",
    "    :param num_samples: number of samples to generate\n",
    "    :param p: Prob(Mediator=1|Action=1), and 1 - Prob(Mediator=1|Action=0).\n",
    "    \"\"\"\n",
    "    beta=1\n",
    "    # Action variable\n",
    "    v0 = np.random.binomial(n=1, p=0.5,size=num_samples)\n",
    "    # Independent gaussian error \n",
    "    eps = np.random.normal(0,1,num_samples)\n",
    "    # Defining the generating function of mediator\n",
    "    def m_func(v0):\n",
    "        return np.where(v0==1, np.random.binomial(n=1, p=p, size=num_samples), \n",
    "                        np.random.binomial(n=1, p=1-p, size=num_samples))\n",
    "    # Generating function for y. Does not depend on action directly.\n",
    "    def y_func(v0, M0):\n",
    "        y =(beta*10)* M0 + eps\n",
    "        return y\n",
    "    M0 = m_func(v0)\n",
    "    y = y_func(v0, M0)\n",
    "    \n",
    "    # Calculate true causal effect\n",
    "    ace = y_func(1, m_func(1)) - y_func(0, m_func(0))\n",
    "    df= pd.DataFrame({\"v0\": v0, \"y\":y})\n",
    "    df[\"M0\"] = M0\n",
    "    df.v0= df.v0.astype('bool')\n",
    "    return df, np.mean(ace)\n",
    "\n",
    "def gen_data_w(num_samples= 1000, p=0.95):\n",
    "    \"\"\"Generate dataset with a common cause confounder.\n",
    "    \n",
    "    :param num_samples: number of samples to generate\n",
    "    :param p: Prob(Action=1|Confounder=1), and 1 - Prob(Action=1|Confounder=0).\n",
    "    \"\"\"\n",
    "    beta=1\n",
    "    # Confounder\n",
    "    W0 = np.random.binomial(n=1, p=0.5,size=num_samples)\n",
    "    # Independent gaussian noise\n",
    "    eps = np.random.normal(0,1,num_samples)\n",
    "    # Generating equation for the action variable\n",
    "    v0 = np.where(W0==1, np.random.binomial(n=1, p=p, size=num_samples), np.random.binomial(n=1, p=1-p, size=num_samples))\n",
    "    # Generating function for y, which depends on both v0 and W0.\n",
    "    def y_func(v0):\n",
    "        y =(beta)* v0 + beta*10*W0 + eps\n",
    "        return y\n",
    "    y = y_func(v0)\n",
    "    \n",
    "    # Calculate true causal effect\n",
    "    ace = y_func(1) - y_func(0)\n",
    "    # create df\n",
    "    df= pd.DataFrame({\"v0\": v0, \"y\":y})\n",
    "    df[\"W0\"] = W0\n",
    "    df.v0= df.v0.astype('bool')\n",
    "    return df, np.mean(ace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def effect(df, action, outcome, var, graph):\n",
    "    \"\"\" Generic wrapper for effect estimation using DoWhy.\n",
    "    \"\"\"\n",
    "    graph = CausalGraph(\n",
    "        treatment_name=action,\n",
    "        outcome_name=outcome,\n",
    "        graph=graph,\n",
    "        observed_node_names=df.columns.tolist()\n",
    "    )\n",
    "    identified_estimand = dowhy.identify_effect(graph, action, outcome)\n",
    "    estimator = LinearRegressionEstimator(\n",
    "        identified_estimand=identified_estimand,\n",
    "        test_significance=None,\n",
    "        evaluate_effect_strength=False\n",
    "    ).fit(\n",
    "        data=df,\n",
    "        treatment_name=[action],\n",
    "        outcome_name=outcome\n",
    "    )\n",
    "\n",
    "    estimate = estimator.estimate_effect(\n",
    "        control_value=0,\n",
    "        treatment_value=1,\n",
    "        target_units=\"ate\",\n",
    "    )\n",
    "    return estimate\n",
    "\n",
    "naive_effects, true_effects, ace_arr = [], [], []\n",
    "for i in range(NUM_SIMS):\n",
    "    df, ace = gen_data_m()\n",
    "    ace_arr.append(ace)\n",
    "    # Data scientist does not know the true graph. Assumes that M0 is a confounder.\n",
    "    #mod=LinearRegression().fit(df[[\"v0\", \"M0\"]], df[\"y\"])\n",
    "    confounder_graph = \"digraph{v0->y;M0->v0; M0->y}\"\n",
    "    mod = effect(df, \"v0\", \"y\", \"M0\", confounder_graph)\n",
    "    naive_effects.append(mod.value)\n",
    "    # Data scientist knows the true graph, where M0 is a mediator.\n",
    "    mediator_graph = \"digraph{v0->M0; M0->y}\"\n",
    "    mod = effect(df, \"v0\", \"y\", \"M0\", mediator_graph)\n",
    "    true_effects.append(mod.value)\n",
    "print(\"ANS\")\n",
    "print(np.mean(naive_effects), np.std(naive_effects))\n",
    "print(np.mean(true_effects), np.std(true_effects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = pd.DataFrame({'Estimated Effect':true_effects, 'Estimator': 'y~t (Correct)'})\n",
    "nd = pd.DataFrame({'Estimated Effect':naive_effects, 'Estimator': \"y~t+m\"})\n",
    "pltd = pd.concat([td,nd], axis=0)\n",
    "sns.set(font_scale=1.75)\n",
    "sns.set_style('whitegrid')\n",
    "gfg= sns.displot(pltd, x=\"Estimated Effect\", kind=\"kde\", hue=\"Estimator\", legend=False)\n",
    "plt.legend(labels=[\"y~t+m\", \"y~t (Correct)\"], bbox_to_anchor=(0.5, 1.02),\n",
    "           borderaxespad=0, title=\"Estimator\",\n",
    "          loc=\"lower center\")\n",
    "plt.axvline(np.mean(ace_arr), linestyle=\"--\")\n",
    "plt.savefig(\"highbias-mediator.pdf\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test (IV)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "\n",
    "def gen_data_iv(num_samples= 1000, p=0.95):\n",
    "    beta=1\n",
    "    Z0 = np.random.binomial(n=1, p=0.5,size=num_samples)\n",
    "    eps = np.random.normal(0,100,num_samples)\n",
    "    W0 = np.random.normal(0,0.4, size=num_samples)\n",
    "    v0 = np.where(sigmoid(Z0*2-1+W0)>=0.5, 1, 0)\n",
    "    def y_func(v0):\n",
    "        y =(beta*10)* v0 + beta*10*W0 + eps\n",
    "        return y\n",
    "    y = y_func(v0)\n",
    "    \n",
    "    # Calculate causal effect\n",
    "    ace = y_func(1) - y_func(0)\n",
    "    print(np.mean(ace), np.std(ace))\n",
    "    df= pd.DataFrame({\"v0\": v0, \"y\":y})\n",
    "    df[\"Z0\"] = Z0\n",
    "    df[\"W0\"] = W0\n",
    "    df.v0= df.v0.astype('bool')\n",
    "    return df, np.mean(ace)\n",
    "\n",
    "\n",
    "naive_effects, true_effects, ace_arr = [], [], []\n",
    "for i in range(100):\n",
    "    df, ace = gen_data_iv()\n",
    "    ace_arr.append(ace)\n",
    "    #print(df.head())\n",
    "    #display(df[\"v0\"].describe())\n",
    "    mod=LinearRegression().fit(df[[\"v0\", \"Z0\", \"W0\"]], df[\"y\"])\n",
    "    #print(mod.coef_)\n",
    "    naive_effects.append(mod.coef_[0])\n",
    "    mod=LinearRegression().fit(df[[\"v0\"]], df[\"y\"])\n",
    "    #print(mod.coef_)\n",
    "    true_effects.append(mod.coef_[0])\n",
    "\n",
    "print(\"ANS\")\n",
    "print(np.mean(naive_effects), np.std(naive_effects))\n",
    "print(np.mean(true_effects), np.std(true_effects))\n",
    "\n",
    "#DML\n",
    "m1 = LinearRegression().fit(df[[ \"Z0\", \"W0\"]], df[\"y\"])\n",
    "yr = df[\"y\"] - m1.predict(df[[ \"Z0\", \"W0\"]])\n",
    "m2 = LinearRegression().fit(df[[ \"Z0\", \"W0\"]], df[\"v0\"])\n",
    "df[\"vr\"] = df[\"v0\"] - m2.predict(df[[ \"Z0\", \"W0\"]])\n",
    "\n",
    "m =  LinearRegression().fit(df[[\"vr\"]], yr)\n",
    "print(m.coef_)\n",
    "\n",
    "print(df.groupby([\"Z0\",\"v0\"]).count())\n",
    "print(df.groupby([\"v0\"]).mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, ace = gen_data_w()\n",
    "print(df.head())\n",
    "mod=LinearRegression().fit(df[[\"v0\"]], df[\"y\"])\n",
    "print(mod.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "td = pd.DataFrame({'Estimated Effect':true_effects, 'Estimator': 'y~t+w (Correct)'})\n",
    "nd = pd.DataFrame({'Estimated Effect':naive_effects, 'Estimator': \"y~t+w+z\"})\n",
    "pltd = pd.concat([td,nd], axis=0)\n",
    "sns.set(font_scale=1.7)\n",
    "sns.set_style('whitegrid')\n",
    "ax= sns.displot(pltd, x=\"Estimated Effect\", kind=\"kde\", hue=\"Estimator\", legend=False)\n",
    "plt.xticks([-200, -100, 0,100,200])\n",
    "plt.legend(labels=[\"y~t+w+z\", \"y~t+w (Correct)\"], bbox_to_anchor=(0.5, 1.02),\n",
    "           borderaxespad=0, title=\"Estimator\",\n",
    "          loc=\"lower center\")\n",
    "#ax.set_xticklabels(labels=[0,10,20], step=50)\n",
    "plt.axvline(np.mean(ace_arr), linestyle=\"--\")\n",
    "plt.savefig('highvariance-iv.pdf', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data_w(num_samples= 1000, p=0.95):\n",
    "    beta=1\n",
    "    W0 = np.random.binomial(n=1, p=0.5,size=num_samples)\n",
    "    eps = np.random.normal(0,1,num_samples)\n",
    "    #v0 = np.where(W0==1, np.random.binomial(n=1, p=p, size=num_samples), np.random.binomial(n=1, p=1-p, size=num_samples))\n",
    "    v0 = np.random.binomial(n=1, p=W0*p + (1-W0)*(1-p), size=num_samples)\n",
    "    def y_func(v0):\n",
    "        y =(beta)* v0 + beta*10*W0 + eps\n",
    "        return y\n",
    "    y = y_func(v0)\n",
    "    \n",
    "    # Calculate causal effect\n",
    "    ace = y_func(1) - y_func(0)\n",
    "    print(np.mean(ace), np.std(ace))\n",
    "    # create df\n",
    "    df= pd.DataFrame({\"v0\": v0, \"y\":y})\n",
    "    df[\"W0\"] = W0\n",
    "    df.v0= df.v0.astype('bool')\n",
    "    return df, np.mean(ace)\n",
    "\n",
    "naive_effects, true_effects = [], []\n",
    "for i in range(100):\n",
    "    df, ace = gen_data_w()\n",
    "    print(df.head())\n",
    "    mod=LinearRegression().fit(df[[\"v0\"]], df[\"y\"])\n",
    "    print(mod.coef_)\n",
    "    mod=LinearRegression().fit(df[[\"v0\", \"w0\"]], df[\"y\"])\n",
    "    print(mod.coef_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
